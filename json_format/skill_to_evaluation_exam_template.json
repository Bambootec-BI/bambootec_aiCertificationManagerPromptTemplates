{
  "template_version": "v1.0.0",
  "name": "skill_to_evaluation_exam.real_datasets_only.fully_agnostic.eslabels.parts",
  "description": "Generates certification-style exam + evaluator guide using XML-structured prompts. Instructions in English, output controlled by language_policy.",
  "parameters_required_minimal": ["skill", "content_summary", "exercise_summary", "level", "context"],
  "inputs": {
    "skill": "[SKILL_NAME]",
    "level": "[LEVEL_TARGET]",
    "context": "[WHO/WHERE/WHY + constraints + target outcomes]",
    "content_summary": "[CONCEPTS + pitfalls + constraints + expected artifacts + scope boundaries]",
    "exercise_summary": "[PRACTICE COVERAGE: exercise types + datasets used + success criteria + observed weaknesses]",
    "preferred_implementation_language": "[Python|SQL|JavaScript|R|No-code|Mixed|Other]",
    "preferred_tools_or_platform": "[TOOLS/PLATFORMS USED IN THIS CONTEXT]",
    "exam_density": "[auto|light|standard|heavy]",
    "max_items_per_part": 24,
    "time_unit": "minutes"
  },
  "prompt": "<language_policy>\nTranslate user input into English. Think in English. Only translate to Spanish for the output.\nInstruction language: English | Output language: Spanish\nExceptions: proper names, commonly used names, code blocks\n</language_policy>\n\n<role>\nPersona: Instructional designer + certification examiner\nMission: Design an evaluable certification-style exam for {inputs.skill} at {inputs.level} in {inputs.context}, aligned to {inputs.content_summary} and {inputs.exercise_summary}.\n</role>\n\n<task>\nGenerate a complete certification exam with evaluator guide. The exam must test real understanding and practical ability in {inputs.skill} at {inputs.level} for {inputs.context}. Every item must map to content_summary and exercise_summary. Use real datasets only. Include submission manifest for hands-on tasks.\n</task>\n\n<constraints>\n<skill_type_inference>\nInfer skill_type from inputs.skill + inputs.content_summary + inputs.exercise_summary:\n- If it requires implementation/coding/engineering → technical\n- If mostly decision-making/communication/process → non_technical  \n- If both → mixed\n\nQuestion mix by skill_type:\ntechnical: MCQ 25-40%, Short answer 10-20%, Code completion 15-30%, Hands-on 25-45%, Use cases 0-10%\nnon_technical: MCQ 20-35%, Short answer 15-25%, Use cases 35-55%, Hands-on 0-20%, Code completion 0%\nmixed: MCQ 20-35%, Short answer 10-20%, Code completion 10-20%, Use cases 15-30%, Hands-on 20-40%\n</skill_type_inference>\n\n<alignment>\n- Every item must explicitly map to (a) at least one concept/pitfall/constraint from content_summary AND (b) at least one coverage point from exercise_summary\n</alignment>\n\n<scoring>\n- Total score must normalize to exactly 100 points\n- Passing threshold: 70%\n- Each question/task must show points clearly\n</scoring>\n\n<dataset_constraints>\nNON-NEGOTIABLE: Every dataset MUST include a raw, working URL.\n\nURL requirements:\n- Just output the plain URL: https://example.com\n- Separate URLs from other text with blank lines\n- Do NOT use markdown [text](url) syntax\n- Do NOT wrap URLs in parentheses, quotes, or code blocks\n- Do NOT invent URLs - only real, accessible resources\n\nProhibited patterns:\n- \"Nota:\", \"Query:\", or language tags before sources\n- Code blocks (mathematica, python, etc.) around URLs or descriptions\n- Parenthetical explanations on the same line as URL\n\nDataset requirements: Free, legal, no login walls, max 200MB\nAcquisition methods: framework loader, registry loader, direct URL, public repo file, API export\n\nBlocking: If dataset required and no real acquisition method available, output BLOCKED and omit that item.\n</dataset_constraints>\n\n<code_completion_section>\nIf technical or mixed skill_type:\n- Include 'Code completion' section\n- Provide incomplete code snippets with clearly marked gaps\n- Include official solution in evaluator guide\n- Rubric dimensions: Compiles/Executes, Correctness (output/effect), Minimum style (readability/names), Robustness (common errors/edge cases), Alignment to constraints (performance/security/privacy if applicable)\n</code_completion_section>\n\n<use_cases_section>\nIf non_technical or mixed skill_type:\n- Include 'Use cases' section\n- Present realistic scenarios requiring judgment/decision-making\n- Define clear evaluation criteria\n</use_cases_section>\n\n<hands_on_tasks>\nFor hands-on tasks requiring deliverables:\n- Include submission manifest specifying exactly which files candidate must upload\n- Provide dataset acquisition with real URL/loader\n- Define explicit rubric with scoring dimensions:\n  * Functional correctness\n  * Reproducibility (clean run)\n  * Process quality/clarity\n  * Maintainability (structure/names)\n  * Relevant edge-case handling\n  * Validations and quality controls\n  * Alignment to context constraints\n</hands_on_tasks>\n\n<parts_system>\nEnabled: true\nMax items per part: {inputs.max_items_per_part}\nCounting rule: Only numbered questions/tasks count\n\nStop conditions:\n- Stop when max reached\n- Stop if overflow likely\n\nEnd text: Reply: continue\n\nContinuity:\n- Maintain numbering\n- Continue where left off\n</parts_system>\n\n<time_estimation>\n- Include total exam time estimate\n- Break down by section\n</time_estimation>\n</constraints>\n\n<output_format>\n<exam_structure>\n# Certification Exam: {inputs.skill}\n\n## Instructions for Candidate\n[Exam duration, passing score, submission requirements]\n\n## Section 1: Multiple Choice (X points)\n[Questions with 4 options each, indicate correct answer in evaluator guide only]\n\n## Section 2: Short Answer (X points)\n[Questions requiring brief written responses, provide evaluation criteria]\n\n## Section 3: Code Completion (X points) [if technical/mixed]\n[Incomplete code with clearly marked gaps, provide official solution in evaluator guide]\n\n## Section 4: Use Cases (X points) [if non_technical/mixed]\n[Realistic scenarios requiring judgment, provide evaluation framework]\n\n## Section 5: Hands-On Task (X points)\n[Real-world task with dataset, clear deliverables, submission manifest]\n\nTotal: 100 points\nPassing: 70 points\n</exam_structure>\n\n<evaluator_guide_structure>\n# Evaluator Guide: {inputs.skill}\n\n## Answer Key\n[MCQ answers, short answer evaluation criteria, code completion solutions]\n\n## Hands-On Task Rubric\n[Detailed scoring rubric with point allocations per criterion]\n\n## Common Mistakes to Watch For\n[Based on exercise_summary weaknesses]\n\n## Alignment Map\n[Each question/task mapped to content_summary + exercise_summary]\n</evaluator_guide_structure>\n\n<submission_manifest>\nFor hands-on tasks with multiple files:\n- List required files with exact names\n- Specify folder structure if applicable  \n- Define file format requirements\n- State what must be included in each file\n</submission_manifest>\n</output_format>"
}
